{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA_RESPONSE = \"llama_response\"\n",
    "QUESTION = \"question\"\n",
    "RESOLUTION_CRITERIA = \"resolution_criteria\"\n",
    "LLAMA_RESPONSE = \"llama_response\"\n",
    "OUTPUT_DIR = Path().resolve() / \"output\"\n",
    "CLEANED_OUTPUT_DIR = Path().resolve() / \"cleaned_output\"\n",
    "GPT35_CSV = Path().resolve().parent / \"inference\" / \"output\" / \"GPT-3.5_sampled_test_set_responses.csv\"\n",
    "assert OUTPUT_DIR.exists()\n",
    "assert GPT35_CSV.exists()\n",
    "CLEANED_OUTPUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = list(OUTPUT_DIR.glob(\"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Here is a forecasting question: {question}\\n\\nHere are the resolution criteria of the question: {resolution_criteria}.\\n\\nBased on the forecasting question and resolution criteria, generate step-by-step reasoning to create a resolution. Output exactly 6 steps without an introduction or a conclusion.\"\"\"  # noqa: E501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_strip(q: str, rc: str, resp: str) -> str:\n",
    "    \"\"\"Strip the prompt from the LlaMA response.\"\"\"\n",
    "    prefix = template.format(question=q, resolution_criteria=rc)\n",
    "    return resp.replace(prefix, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output_file in output_files:\n",
    "    df_llama = pd.read_csv(output_file)\n",
    "    df_llama[LLAMA_RESPONSE] = df_llama.apply(lambda row: left_strip(row[QUESTION], row[RESOLUTION_CRITERIA], row[LLAMA_RESPONSE]), axis=1)\n",
    "    df_llama.to_csv(CLEANED_OUTPUT_DIR / (\"cleaned_\" + output_file.name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
